{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip -q install wandb\n",
        "!wandb login"
      ],
      "metadata": {
        "id": "GewU2jZfccP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvGU55tjPBIL"
      },
      "source": [
        "# Data import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-o6F32HcPBIM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import ConvNextImageProcessor, ConvNextForImageClassification\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import copy\n",
        "from copy import deepcopy\n",
        "try:\n",
        "  import wandb\n",
        "except ImportError:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfVQiAILT0VP"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle\n",
        "!mkdir /.kaggle\n",
        "!mv kaggle.json /.kaggle\n",
        "!mv /.kaggle /root/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVf_0eZtTAOz"
      },
      "outputs": [],
      "source": [
        "!kaggle competitions download -c dlmi-lymphocytosis-classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppyr46tEUbKT"
      },
      "outputs": [],
      "source": [
        "!unzip /content/dlmi-lymphocytosis-classification.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIbNMVCpfj-R"
      },
      "outputs": [],
      "source": [
        "!wget -P /content/ -O test_df_features.csv https://www.dropbox.com/scl/fi/xq4n2smw8l72ia02brxhh/test_df_features.csv?rlkey=zxe6i34f6cu0oq0vxy77ixlfl&dl=0\n",
        "!wget -P /content/ -O train_df_features.csv https://www.dropbox.com/scl/fi/vh72tl6skb8ncx3c22qx5/train_df_features.csv?rlkey=lc5ijt3y01x2g76qzb94z0odp&dl=0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aR-eha_AE-BQ"
      },
      "source": [
        "# Creation of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZ_1_wyIHif0"
      },
      "outputs": [],
      "source": [
        "class PatientDataset(Dataset):\n",
        "    \"\"\"\n",
        "    For each patient get a dict with:\n",
        "    - 'images': list of different images,\n",
        "    - 'age': age\n",
        "    - 'lymph_count': lymph_count\n",
        "    - 'gender': gender - can be useful\n",
        "    - 'label': label - useful during training, useless during test\n",
        "    - 'id': id - useless during training, usefull during test for submission\n",
        "    \"\"\"\n",
        "    def __init__(self, csv_file, root_dir, feat_file, transform=None, ids = None):\n",
        "        self.data_frame = pd.read_csv(csv_file)\n",
        "        self.data_frame['GENDER'] = self.data_frame['GENDER'].replace(['f'],['F']) # Some samples were labeled as 'f' instead of 'F'\n",
        "        self.df_feats = pd.read_csv(feat_file)\n",
        "        self.data_frame = pd.merge(self.data_frame, self.df_feats, on='ID')\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.ids = ids\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.ids is not None:\n",
        "          return len(self.ids)\n",
        "        else:\n",
        "          return len(self.data_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        if self.ids is not None:\n",
        "          idx = self.ids[idx]\n",
        "\n",
        "        img_dir = os.path.join(self.root_dir, self.data_frame.iloc[idx, 0])\n",
        "        images = [Image.open(os.path.join(img_dir, img_name)) for img_name in os.listdir(img_dir)]\n",
        "\n",
        "        id = self.data_frame.iloc[idx, 0]\n",
        "        label = self.data_frame.iloc[idx, 1]\n",
        "        gender = 1 if self.data_frame.iloc[idx, 2] == 'M' else 0\n",
        "        age = self.calculate_age(self.data_frame.iloc[idx, 3])\n",
        "        lymph_count = self.data_frame.iloc[idx, 4]\n",
        "        features = eval(self.data_frame.iloc[idx, 5])\n",
        "        features = torch.tensor(features, dtype=torch.float32)\n",
        "\n",
        "        sample = {'images': images, 'age': age, 'lymph_count': lymph_count, 'gender': gender, 'features': features, 'label': label, 'id': id}\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def calculate_age(self, dob):\n",
        "        year = int(dob[-4:])\n",
        "        return 2024-year\n",
        "\n",
        "class TestTransform(object):\n",
        "  \"\"\" Useful class to turn our image into tensor \"\"\"\n",
        "  def __call__(self, sample):\n",
        "    images, age, lymph_count, gender, features, label, id = sample['images'], sample['age'], sample['lymph_count'], sample['gender'], sample['features'], sample['label'], sample['id']\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                                  ])\n",
        "\n",
        "    images = [transform(img) for img in images]\n",
        "\n",
        "    return {'images': images, 'age': age, 'lymph_count': lymph_count, 'gender': gender, 'features': features, 'label': label, 'id': id}\n",
        "\n",
        "class TrainTransform(object):\n",
        "  def __call__(self, sample):\n",
        "    images, age, lymph_count, gender, features, label, id = sample['images'], sample['age'], sample['lymph_count'], sample['gender'], sample['features'], sample['label'], sample['id']\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "                                    transforms.RandomHorizontalFlip(),\n",
        "                                    transforms.RandomVerticalFlip(),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                                  ])\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "                                    transforms.ToTensor()\n",
        "                                  ])\n",
        "\n",
        "    images = [transform(img) for img in images]\n",
        "\n",
        "    return {'images': images, 'age': age, 'lymph_count': lymph_count, 'gender': gender, 'features': features, 'label': label, 'id': id}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiTRMhPQ4azC"
      },
      "outputs": [],
      "source": [
        "testset = PatientDataset(csv_file='/content/testset/testset_data.csv',\n",
        "                         root_dir='/content/testset/',\n",
        "                         transform=transforms.Compose([\n",
        "                             TestTransform(),\n",
        "                         ]),\n",
        "                         feat_file='/content/test_df_features.csv')\n",
        "\n",
        "testloader = DataLoader(testset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ida4eDN34GgT"
      },
      "outputs": [],
      "source": [
        "def k_fold_unbalanced(dataframe, nb_folds=5, seed=None):\n",
        "  \"\"\"\n",
        "  Return k fold trainset, testset unbalanced: with the same distribution\n",
        "  \"\"\"\n",
        "  if seed is not None:\n",
        "    np.random.seed(seed)\n",
        "\n",
        "  n_0 = dataframe.groupby('LABEL').nunique()['ID'][0]\n",
        "  p_0 = n_0/len(dataframe)\n",
        "  n_1 = dataframe.groupby('LABEL').nunique()['ID'][1]\n",
        "  p_1 = n_1/len(dataframe)\n",
        "  train_datasets_list = list()\n",
        "  val_datasets_list = list()\n",
        "  n_list = list()\n",
        "  # Pick ids depending on sizes and proportions\n",
        "  shuffled_0 = dataframe.index[dataframe['LABEL']==0].tolist()\n",
        "  np.random.shuffle(shuffled_0)\n",
        "  shuffled_1 = dataframe.index[dataframe['LABEL']==1].tolist()\n",
        "  np.random.shuffle(shuffled_1)\n",
        "  fold_size_0 = n_0 // nb_folds\n",
        "  nb_remained_0 = n_0 % nb_folds\n",
        "  start_ind_0 = 0\n",
        "  fold_size_1 = n_1 // nb_folds\n",
        "  nb_remained_1 = n_1 % nb_folds\n",
        "  start_ind_1 = 0\n",
        "\n",
        "  for i in range(nb_folds):\n",
        "\n",
        "\n",
        "    if nb_remained_0 > 0:\n",
        "      i_fold_size_0 = fold_size_0 + 1\n",
        "      nb_remained_0 -= 1\n",
        "    else:\n",
        "      i_fold_size_0 = fold_size_0\n",
        "\n",
        "    if nb_remained_1 > 0:\n",
        "      i_fold_size_1 = fold_size_1 + 1\n",
        "      nb_remained_1 -= 1\n",
        "    else:\n",
        "      i_fold_size_1 = fold_size_1\n",
        "\n",
        "    end_ind_0 = start_ind_0 + i_fold_size_0\n",
        "    end_ind_1 = start_ind_1 + i_fold_size_1\n",
        "    train_0 = shuffled_0[start_ind_0: end_ind_0]\n",
        "    train_1 = shuffled_1[start_ind_1: end_ind_1]\n",
        "\n",
        "    train_ids = train_0 + train_1\n",
        "    np.random.shuffle(train_ids)\n",
        "\n",
        "    train_dataframe=dataframe.loc[train_ids]\n",
        "\n",
        "    n_0_train = train_dataframe.groupby('LABEL').nunique()['ID'][0]\n",
        "    n_1_train = train_dataframe.groupby('LABEL').nunique()['ID'][1]\n",
        "\n",
        "    train_dataset = PatientDataset(csv_file='trainset/trainset_true.csv',\n",
        "                                   root_dir='trainset/',\n",
        "                                   transform=transforms.Compose([\n",
        "                                       TrainTransform(),\n",
        "                                   ]),\n",
        "                                   feat_file='train_df_features.csv',\n",
        "                                   ids=train_ids)\n",
        "\n",
        "    val_dataset = PatientDataset(csv_file='trainset/trainset_true.csv',\n",
        "                                 root_dir='trainset/',\n",
        "                                 transform=transforms.Compose([\n",
        "                                     TestTransform(),\n",
        "                                 ]),\n",
        "                                 feat_file='train_df_features.csv',\n",
        "                                 ids=train_ids)\n",
        "\n",
        "    train_datasets_list.append(train_dataset)\n",
        "    val_datasets_list.append(val_dataset)\n",
        "    n_list.append((n_0_train, n_1_train))\n",
        "\n",
        "  return train_datasets_list, val_datasets_list, n_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iez0toXR4UhK"
      },
      "outputs": [],
      "source": [
        "dataframe = pd.read_csv('/content/trainset/trainset_true.csv')\n",
        "dataframe['GENDER'] = dataframe['GENDER'].replace(['f'],['F'])\n",
        "nb_folds = 2\n",
        "\n",
        "train_datasets_list, val_datasets_list, n_list = k_fold_unbalanced(dataframe, nb_folds)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PkROhnxPsB5"
      },
      "outputs": [],
      "source": [
        "def split_train_val_balanced(dataframe, p_val=0.2):\n",
        "  \"\"\"\n",
        "  Split a dataset in a trainset and a valset which is balanced\n",
        "  \"\"\"\n",
        "  n_0 = dataframe.groupby('LABEL').nunique()['ID'][0]\n",
        "  n_1 = dataframe.groupby('LABEL').nunique()['ID'][1]\n",
        "  nb_val = int(p_val * (n_0 + n_1))\n",
        "  # Pick ids depending on sizes and proportions\n",
        "  shuffled_0 = dataframe.index[dataframe['LABEL']==0].tolist()\n",
        "  np.random.shuffle(shuffled_0)\n",
        "  shuffled_1 = dataframe.index[dataframe['LABEL']==1].tolist()\n",
        "  np.random.shuffle(shuffled_1)\n",
        "\n",
        "\n",
        "  val_0 = shuffled_0[: nb_val // 2]\n",
        "  val_1 = shuffled_1[: nb_val // 2]\n",
        "  val_ids = val_0 + val_1\n",
        "  np.random.shuffle(val_ids)\n",
        "\n",
        "  val_dataframe = dataframe.loc[val_ids]\n",
        "  n_0_val = val_dataframe.groupby('LABEL').nunique()['ID'][0]\n",
        "  n_1_val = val_dataframe.groupby('LABEL').nunique()['ID'][1]\n",
        "\n",
        "  train_0 = shuffled_0[nb_val // 2:]\n",
        "  train_1 = shuffled_1[nb_val // 2:]\n",
        "  train_ids = train_0 + train_1\n",
        "  np.random.shuffle(train_ids)\n",
        "\n",
        "  train_dataframe = dataframe.loc[train_ids]\n",
        "  n_0_train = train_dataframe.groupby('LABEL').nunique()['ID'][0]\n",
        "  n_1_train = train_dataframe.groupby('LABEL').nunique()['ID'][1]\n",
        "\n",
        "  train_dataset = PatientDataset(csv_file='trainset/trainset_true.csv',\n",
        "                                root_dir='trainset/',\n",
        "                                transform=transforms.Compose([\n",
        "                                    TrainTransform(),\n",
        "                                ]),\n",
        "                                feat_file='train_df_features.csv',\n",
        "                                ids=train_ids)\n",
        "\n",
        "  val_dataset = PatientDataset(csv_file='trainset/trainset_true.csv',\n",
        "                                root_dir='trainset/',\n",
        "                                transform=transforms.Compose([\n",
        "                                    TestTransform(),\n",
        "                                ]),\n",
        "                                feat_file='train_df_features.csv',\n",
        "                                ids=val_ids)\n",
        "\n",
        "  return train_dataset, val_dataset, n_0_train, n_1_train, n_0_val, n_1_val"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_train_val(dataframe, p_val=0.5, seed=None):\n",
        "  \"\"\"\n",
        "  Classic split train val set\n",
        "  \"\"\"\n",
        "  if seed is not None:\n",
        "    np.random.seed(seed)\n",
        "  n_0 = dataframe.groupby('LABEL').nunique()['ID'][0]\n",
        "  n_1 = dataframe.groupby('LABEL').nunique()['ID'][1]\n",
        "  nb_val = int(p_val * (n_0 + n_1))\n",
        "  # Pick ids depending on sizes and proportions\n",
        "  shuffled = dataframe.index.tolist()\n",
        "  np.random.shuffle(shuffled)\n",
        "  val_ids = shuffled[: nb_val]\n",
        "  np.random.shuffle(val_ids)\n",
        "  val_dataframe = dataframe.loc[val_ids]\n",
        "  n_0_val = val_dataframe.groupby('LABEL').nunique()['ID'][0]\n",
        "  n_1_val = val_dataframe.groupby('LABEL').nunique()['ID'][1]\n",
        "\n",
        "  train_ids = shuffled[nb_val:]\n",
        "  np.random.shuffle(train_ids)\n",
        "  train_dataframe = dataframe.loc[train_ids]\n",
        "  n_0_train = train_dataframe.groupby('LABEL').nunique()['ID'][0]\n",
        "  n_1_train = train_dataframe.groupby('LABEL').nunique()['ID'][1]\n",
        "\n",
        "  train_dataset = PatientDataset(csv_file='trainset/trainset_true.csv',\n",
        "                                 root_dir='trainset/',\n",
        "                                 transform=transforms.Compose([\n",
        "                                     TrainTransform(),\n",
        "                                 ]),\n",
        "                                 feat_file='train_df_features.csv',\n",
        "                                 ids=train_ids)\n",
        "\n",
        "  val_dataset = PatientDataset(csv_file='trainset/trainset_true.csv',\n",
        "                               root_dir='trainset/',\n",
        "                               transform=transforms.Compose([\n",
        "                                   TestTransform(),\n",
        "                               ]),\n",
        "                               feat_file='train_df_features.csv',\n",
        "                               ids=val_ids)\n",
        "\n",
        "  return train_dataset, val_dataset, n_0_train, n_1_train, n_0_val, n_1_val"
      ],
      "metadata": {
        "id": "YR3k9iiBa2r5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fl4v__ZKfksI"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1buRFyZ2V7vB"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "class ResNetOneTaskModel(nn.Module):\n",
        "    def __init__(self, ):\n",
        "      super(ResNetOneTaskModel, self).__init__()\n",
        "      # Load the feature extractor: ResNet\n",
        "      self.feature_extractor = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "      self.feature_extractor = torch.nn.Sequential(*list(self.feature_extractor.children())[:-1])\n",
        "      self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "      self.classifier_image = nn.Sequential(nn.Linear(512, 1),\n",
        "                                            nn.Sigmoid())\n",
        "\n",
        "      self.classifier_feats = nn.Sequential(nn.Linear(8+2, 64),\n",
        "                                            nn.ReLU(),\n",
        "                                            nn.Linear(64, 1),\n",
        "                                            nn.Sigmoid())\n",
        "\n",
        "      self.image_to_scalar = nn.Linear(512, 1)\n",
        "\n",
        "      self.feat_to_scalar = nn.Linear(8, 1)\n",
        "\n",
        "      self.gate = nn.Sequential(nn.Linear(2+1+1, 1),\n",
        "                                nn.Sigmoid())\n",
        "\n",
        "      self.encoder_feats = nn.Sequential(nn.Linear(51, 32),\n",
        "                                         nn.ReLU(),\n",
        "                                         nn.Linear(32, 16),\n",
        "                                         nn.ReLU(),\n",
        "                                         nn.Linear(16, 8))\n",
        "\n",
        "    def forward(self, images, age, lymph_count, gender, features, return_everything=False):\n",
        "      images_encoded = torch.stack([self.feature_extractor(image.to(self.device)).squeeze((2, 3)) for image in images], dim=0) # chaque image encodée est de shape (batch_size, 512)\n",
        "      images_agg = torch.mean(images_encoded, dim=0)\n",
        "      y_images = self.classifier_image(images_agg)\n",
        "      feats_encoded = torch.stack([self.encoder_feats(features[:, i]) for i in range(features.shape[1])], dim=0)\n",
        "      feats_agg = torch.mean(feats_encoded, dim=0)\n",
        "      metadata = torch.cat([age, lymph_count], dim=0).unsqueeze(dim=0).float()\n",
        "      all_feat = torch.cat([metadata, feats_agg], dim=1)\n",
        "      y_feat = self.classifier_feats(all_feat)\n",
        "      image_scalar = self.image_to_scalar(images_agg)\n",
        "      feat_scalar = self.feat_to_scalar(feats_agg)\n",
        "      pi_images = self.gate(torch.cat([metadata, image_scalar, feat_scalar], dim=1))\n",
        "      pi_feat = 1 - pi_images\n",
        "      y_hat = pi_images * y_images + pi_feat * y_feat\n",
        "\n",
        "      if return_everything:\n",
        "        return y_hat, y_images, y_feat, pi_feat, pi_images\n",
        "\n",
        "      return y_hat"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "class ResNetMultiTaskModel(nn.Module):\n",
        "    def __init__(self, ):\n",
        "      super(ResNetMultiTaskModel, self).__init__()\n",
        "\n",
        "      self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "      # Load the feature extractor: ResNet\n",
        "      self.feature_extractor = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "      self.feature_extractor = torch.nn.Sequential(*list(self.feature_extractor.children())[:-1])\n",
        "\n",
        "      self.classifier_image = nn.Sequential(nn.Linear(512, 128),\n",
        "                                            nn.ReLU(),\n",
        "                                            nn.Linear(128, 1),\n",
        "                                            nn.Sigmoid())\n",
        "\n",
        "      self.classifier_data = nn.Sequential(nn.Linear(8+2, 64),\n",
        "                                           nn.ReLU(),\n",
        "                                           nn.Linear(64, 1),\n",
        "                                           nn.Sigmoid())\n",
        "\n",
        "      self.regressor_image = nn.Linear(512, 1)\n",
        "\n",
        "      self.image_to_scalar = nn.Sequential(nn.Linear(512, 128),\n",
        "                                           nn.ReLU(),\n",
        "                                           nn.Linear(128, 1))\n",
        "\n",
        "      self.data_to_scalar = nn.Linear(8, 1)\n",
        "\n",
        "      self.gate = nn.Sequential(nn.Linear(2, 1),\n",
        "                                nn.Sigmoid())\n",
        "\n",
        "      self.encoder_data = nn.Sequential(nn.Linear(51, 32),\n",
        "                                        nn.ReLU(),\n",
        "                                        nn.Linear(32, 16),\n",
        "                                        nn.ReLU(),\n",
        "                                        nn.Linear(16, 8))\n",
        "\n",
        "    def forward(self, images, age, lymph_count, gender, features, return_everything=False):\n",
        "      # About the images\n",
        "      images_encoded = torch.stack([self.feature_extractor(image.to(self.device)).squeeze((2, 3)) for image in images], dim=0)\n",
        "      images_agg = torch.mean(images_encoded, dim=0)\n",
        "      y_images = self.classifier_image(images_agg)\n",
        "      reg_img = self.regressor_image(images_agg)\n",
        "      image_scalar = self.image_to_scalar(images_agg)\n",
        "\n",
        "      # About the scalar data\n",
        "      data_encoded = torch.stack([self.encoder_data(features[:, i]) for i in range(features.shape[1])], dim=0)\n",
        "      data_agg = torch.mean(data_encoded, dim=0)\n",
        "      metadata = torch.cat([age, lymph_count], dim=0).unsqueeze(dim=0).float()\n",
        "      all_feat = torch.cat([metadata, data_agg], dim=1)\n",
        "      y_data = self.classifier_data(all_feat)\n",
        "      data_scalar = self.data_to_scalar(data_agg)\n",
        "\n",
        "      # Gate\n",
        "      pi_images = self.gate(torch.cat([data_scalar, image_scalar], dim=1))\n",
        "      pi_data = 1 - pi_images\n",
        "      y_hat = pi_images * y_images + pi_data * y_data\n",
        "\n",
        "      if return_everything:\n",
        "        return y_hat, y_images, y_data, pi_data, pi_images\n",
        "\n",
        "      return y_hat, reg_img"
      ],
      "metadata": {
        "id": "SvbGZGQT6RHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1NTGL_6LO2J"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import convnext_tiny, ConvNeXt_Tiny_Weights\n",
        "\n",
        "class ConvNextMultiTaskModel(nn.Module):\n",
        "    def __init__(self, ):\n",
        "      super(ConvNextMultiTaskModel, self).__init__()\n",
        "      # Load the feature extractor: ResNet\n",
        "      self.feature_extractor = convnext_tiny(weights = ConvNeXt_Tiny_Weights.DEFAULT)\n",
        "      self.feature_extractor = torch.nn.Sequential(*list(self.feature_extractor.children())[:-1])\n",
        "      # Freeze feature extractor\n",
        "      for param in self.feature_extractor.parameters():\n",
        "            param.requires_grad = False\n",
        "      self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "      self.feature_common_embedding = nn.Linear(768,128)\n",
        "      self.classifier_image = nn.Sequential(nn.Linear(128, 1),\n",
        "                                            nn.Sigmoid())\n",
        "\n",
        "      self.regressor_image = nn.Sequential(nn.Linear(128, 1))\n",
        "\n",
        "      self.classifier_feats = nn.Sequential(nn.Linear(8+2, 64),\n",
        "                                            nn.ReLU(),\n",
        "                                            nn.Linear(64, 1),\n",
        "                                            nn.Sigmoid())\n",
        "\n",
        "      self.image_to_scalar = nn.Linear(128, 1)\n",
        "\n",
        "      self.feat_to_scalar = nn.Linear(8, 1)\n",
        "\n",
        "      self.gate = nn.Sequential(nn.Linear(2+1+1, 1),\n",
        "                                nn.Sigmoid())\n",
        "\n",
        "      self.encoder_feats = nn.Sequential(nn.Linear(51, 32),\n",
        "                                         nn.ReLU(),\n",
        "                                         nn.Linear(32, 16),\n",
        "                                         nn.ReLU(),\n",
        "                                         nn.Linear(16, 8))\n",
        "\n",
        "    def forward(self, images, age, lymph_count, gender, features):\n",
        "      images_encoded = torch.stack([self.feature_common_embedding((self.feature_extractor(image.to(self.device))).squeeze((2, 3))) for image in images], dim=0) # chaque image encodée est de shape (batch_size, 512)\n",
        "      images_agg = torch.mean(images_encoded, dim=0)\n",
        "      y_images = self.classifier_image(images_agg)\n",
        "      reg_img = self.regressor_image(images_agg)\n",
        "      feats_encoded = torch.stack([self.encoder_feats(features[:, i]) for i in range(features.shape[1])], dim=0)\n",
        "      feats_agg = torch.mean(feats_encoded, dim=0)\n",
        "      metadata = torch.cat([age, lymph_count], dim=0).unsqueeze(dim=0).float()\n",
        "      all_feat = torch.cat([metadata, feats_agg], dim=1)\n",
        "      y_feat = self.classifier_feats(all_feat)\n",
        "      image_scalar = self.image_to_scalar(images_agg)\n",
        "      feat_scalar = self.feat_to_scalar(feats_agg)\n",
        "      pi_images = self.gate(torch.cat([metadata, image_scalar, feat_scalar], dim=1))\n",
        "      pi_feat = 1 - pi_images\n",
        "      y_hat = pi_images * y_images + pi_feat * y_feat\n",
        "\n",
        "      return y_hat, reg_img"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "import timm\n",
        "\n",
        "class LoRA(nn.Module):\n",
        "    def __init__(self, linear_layer, in_dim, rank=32, alpha=16):\n",
        "        super(LoRA, self).__init__()\n",
        "        ##### START CODE #####\n",
        "        self.linear_layer = linear_layer\n",
        "        std = 1 / torch.sqrt(torch.tensor(rank).float())\n",
        "        self.adapter_Q_downsample = nn.Parameter((torch.randn((in_dim,rank))*std).to(device))\n",
        "        self.adapter_Q_upsample = nn.Parameter(torch.zeros((rank,in_dim)).to(device))\n",
        "        self.adapter_V_downsample = nn.Parameter((torch.randn((in_dim,rank))*std).to(device))\n",
        "        self.adapter_V_upsample = nn.Parameter(torch.zeros((rank,in_dim)).to(device))\n",
        "        self.adapter_alpha = alpha\n",
        "        ##### END CODE #####\n",
        "\n",
        "    def forward(self, x):\n",
        "        ##### START CODE #####\n",
        "        x_q = self.adapter_alpha * (x @ self.adapter_Q_downsample @ self.adapter_Q_upsample)\n",
        "        x_v = self.adapter_alpha * (x @ self.adapter_V_downsample @ self.adapter_V_upsample)\n",
        "        x_lora = torch.cat([x_q, torch.zeros_like(x_v), x_v], dim=-1)\n",
        "        x = self.linear_layer(x) + x_lora\n",
        "        return x\n",
        "        ##### END CODE #####\n",
        "\n",
        "def add_lora(model):\n",
        "    ##### START CODE #####\n",
        "    for block in model.blocks:\n",
        "        block.attn.qkv = LoRA(block.attn.qkv, block.attn.qkv.in_features).to(device)\n",
        "\n",
        "def freeze_model_lora(model):\n",
        "    ##### START CODE #####\n",
        "    for name, param in model.named_parameters():\n",
        "        if not('adapter' in name):\n",
        "            param.requires_grad = False\n",
        "\n",
        "    ##### END CODE #####\n",
        "\n",
        "\n",
        "class VitMultiTaskLoraModel(nn.Module):\n",
        "    def __init__(self, ):\n",
        "      super(VitMultiTaskLoraModel, self).__init__()\n",
        "      # Load the feature extractor: ConvNext\n",
        "      self.feature_extractor = timm.create_model('vit_base_patch16_224', pretrained=True).to(device)\n",
        "      # add LoRa to feature extractor\n",
        "      add_lora(self.feature_extractor)\n",
        "      freeze_model_lora(self.feature_extractor)\n",
        "      self.feature_extractor.head = nn.Identity()\n",
        "      self.classifier_image = nn.Sequential(nn.Linear(768, 1),\n",
        "                                            nn.Sigmoid())\n",
        "\n",
        "      self.regressor_image = nn.Sequential(nn.Linear(768, 1))\n",
        "\n",
        "      self.classifier_feats = nn.Sequential(nn.Linear(8+2, 64),\n",
        "                                            nn.ReLU(),\n",
        "                                            nn.Linear(64, 1),\n",
        "                                            nn.Sigmoid())\n",
        "\n",
        "      self.image_to_scalar = nn.Linear(768, 1)\n",
        "\n",
        "      self.feat_to_scalar = nn.Linear(8, 1)\n",
        "\n",
        "      self.gate = nn.Sequential(nn.Linear(2+1+1, 1),\n",
        "                                nn.Sigmoid())\n",
        "\n",
        "      self.encoder_feats = nn.Sequential(nn.Linear(51, 32),\n",
        "                                         nn.ReLU(),\n",
        "                                         nn.Linear(32, 16),\n",
        "                                         nn.ReLU(),\n",
        "                                         nn.Linear(16, 8))\n",
        "\n",
        "    def forward(self, images, age, lymph_count, gender, features):\n",
        "      images_encoded = torch.stack([(self.feature_extractor(image.to(device))) for image in images], dim=0) # chaque image encodée est de shape (batch_size, 512)\n",
        "      images_agg = torch.mean(images_encoded, dim=0)\n",
        "      y_images = self.classifier_image(images_agg)\n",
        "      reg_img = self.regressor_image(images_agg)\n",
        "      feats_encoded = torch.stack([self.encoder_feats(features[:, i]) for i in range(features.shape[1])], dim=0)\n",
        "      feats_agg = torch.mean(feats_encoded, dim=0)\n",
        "      metadata = torch.cat([age, lymph_count], dim=0).unsqueeze(dim=0).float()\n",
        "      all_feat = torch.cat([metadata, feats_agg], dim=1)\n",
        "      y_feat = self.classifier_feats(all_feat)\n",
        "      image_scalar = self.image_to_scalar(images_agg)\n",
        "      feat_scalar = self.feat_to_scalar(feats_agg)\n",
        "      pi_images = self.gate(torch.cat([metadata, image_scalar, feat_scalar], dim=1))\n",
        "      pi_feat = 1 - pi_images\n",
        "      y_hat = pi_images * y_images + pi_feat * y_feat\n",
        "\n",
        "      return y_hat, reg_img"
      ],
      "metadata": {
        "id": "WpDUHwCRCkDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zGRN1ZJ-YoV"
      },
      "outputs": [],
      "source": [
        "def weighted_binary_cross_entropy(output, target, weights=None):\n",
        "\n",
        "  output = torch.clamp(output, 1e-7, 1-1e-7)\n",
        "\n",
        "  if weights is not None:\n",
        "    loss = weights[1] * (target * torch.log(output)) + weights[0] * ((1 - target) * torch.log(1 - output))\n",
        "\n",
        "  else:\n",
        "    loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)\n",
        "\n",
        "  return torch.neg(torch.mean(loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbA5EGJQQUdK"
      },
      "outputs": [],
      "source": [
        "def nmse_loss(output, target):\n",
        "    numerator = torch.sum((target - output) ** 2)\n",
        "    denominator = torch.sum(target ** 2)\n",
        "    return numerator / denominator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZBjSGMKX6vz"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FByCz3WLRnhE"
      },
      "source": [
        "## Cross validation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = pd.read_csv('/content/trainset/trainset_true.csv')\n",
        "dataframe['GENDER'] = dataframe['GENDER'].replace(['f'],['F'])\n",
        "nb_folds = 5\n",
        "\n",
        "train_datasets_list, val_datasets_list, n_list = k_fold_unbalanced(dataframe, nb_folds)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "uPFbAyJo81_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FO7tJ0IX9Ik"
      },
      "outputs": [],
      "source": [
        "def cv_multitask(train_datasets_list, val_datasets_list, n_list, name_model, device, batch_size=1, lr=1e-3, max_epochs=100, patience_early_stopping=10, patience_lr=5, lr_decay=0.1, score=0):\n",
        "\n",
        "  nb_folds = len(train_datasets_list)\n",
        "\n",
        "  for i in range(nb_folds):\n",
        "    print('----------------------------------------------------------')\n",
        "    print(f'Fold number {i+1}')\n",
        "    print('----------------------------------------------------------')\n",
        "    if name_model == \"ConvNextMultiTaskModel\":\n",
        "      model = ConvNextMultiTaskModel()\n",
        "    elif name_model == \"ResNetMultiTaskModel\":\n",
        "      model = ResNetMultiTaskModel()\n",
        "    elif name_model == \"VitMultiTaskLoraModel\":\n",
        "      model = VitMultiTaskLoraModel()\n",
        "    model.to(device)\n",
        "    valset = val_datasets_list[i]\n",
        "    valloader = DataLoader(valset, shuffle=True)\n",
        "    n_0_val, n_1_val = n_list[i]\n",
        "    trainset = torch.utils.data.ConcatDataset([train_datasets_list[j] for j in range(nb_folds) if j !=i])\n",
        "    trainloader = DataLoader(trainset, shuffle=True)\n",
        "    n_0_train, n_1_train = np.array([n_list[j] for j in range(nb_folds) if j!=i]).sum(axis=0)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    n_train = n_0_train + n_1_train\n",
        "    weights_train = torch.Tensor([n_train/n_0_train, n_train/n_1_train])\n",
        "    n_val = n_0_val + n_1_val\n",
        "    weights_val = torch.Tensor([n_val/n_0_val, n_val/n_1_val])\n",
        "\n",
        "    best_val_loss = 1e8\n",
        "    n_wt_improvement_lr = 0 # Nombre d'epoch consécutives sans dépasser le meilleur score depuis le dernier changement de lr\n",
        "    n_wt_improvement_stop = 0 # Nombre d'epoch consécutives sans dépasser le meilleur score\n",
        "    best_dict = deepcopy(model.state_dict())\n",
        "    best_b_acc = 0\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "      print(f'Epoch: {epoch+1}')\n",
        "\n",
        "      model.train()\n",
        "      train_loss = 0\n",
        "      train_class_loss = 0\n",
        "      train_reg_loss = 0\n",
        "      train_acc = 0\n",
        "      train_b_acc = 0\n",
        "      loss = 0\n",
        "      for i, data in enumerate(tqdm(trainloader, desc=\"Train\")):\n",
        "        images, age, lymph_count, gender, features = data['images'], data['age'].to(device), data['lymph_count'].to(device), data['gender'].to(device), data['features'].to(device)\n",
        "        y_hat, reg_hat = model(images, age, lymph_count, gender, features)\n",
        "        y_hat, reg_hat = y_hat.to(device), reg_hat.to(device)\n",
        "        y_true = data['label'].float().unsqueeze(0).to(device)\n",
        "        loss_classification = weighted_binary_cross_entropy(y_hat, y_true, weights=weights_train)\n",
        "        loss_reg = nmse_loss(reg_hat, lymph_count)\n",
        "        loss += loss_classification + loss_reg\n",
        "        train_loss += loss_classification.item() + loss_reg.item()\n",
        "        train_class_loss += loss_classification.item()\n",
        "        train_reg_loss += loss_reg.item()\n",
        "        if (i+1) % batch_size ==0:\n",
        "          loss /= batch_size\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          optimizer.zero_grad()\n",
        "          loss = 0\n",
        "        elif (i+1) == len(trainloader):\n",
        "          loss /= (len(trainloader) % batch_size)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          optimizer.zero_grad()\n",
        "          loss = 0\n",
        "        pred = torch.round(y_hat)\n",
        "        train_b_acc += 0.5*(1/n_0_train)*(pred.int() == y_true.int()).sum().item() if y_true.int() == 0 else 0.5*(1/n_1_train)*(pred.int() == y_true.int()).sum().item()\n",
        "        train_acc += (pred.int() == y_true.int()).sum().item()\n",
        "\n",
        "      train_acc /= len(trainloader)\n",
        "      train_loss /= len(trainloader)\n",
        "      train_class_loss /= len(trainloader)\n",
        "      train_reg_loss /= len(trainloader)\n",
        "      train_b_acc = np.round(train_b_acc, 3)\n",
        "      train_acc = np.round(train_acc, 3)\n",
        "      train_loss = np.round(train_loss, 3)\n",
        "      train_class_loss = np.round(train_class_loss, 3)\n",
        "      train_reg_loss = np.round(train_reg_loss, 3)\n",
        "      print(f'Train balanced accuracy: {train_b_acc}, Train accuracy: {train_acc}, Train loss: {train_loss}, Train classification loss: {train_class_loss}, Train regression loss: {train_reg_loss}')\n",
        "\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "        val_loss =  0\n",
        "        val_acc = 0\n",
        "        val_b_acc = 0\n",
        "        val_reg_loss = 0\n",
        "        val_class_loss = 0\n",
        "        for data in tqdm(valloader, desc=\"Validation\"):\n",
        "          images, age, lymph_count, gender, features = data['images'], data['age'].to(device), data['lymph_count'].to(device), data['gender'].to(device), data['features'].to(device)\n",
        "          y_hat, reg_hat = model(images, age, lymph_count, gender, features)\n",
        "          y_hat = y_hat.to(device)\n",
        "          reg_hat = reg_hat.to(device)\n",
        "          y_true = data['label'].float().to(device)\n",
        "          loss_classification = weighted_binary_cross_entropy(y_hat, y_true, weights=weights_val)\n",
        "          loss_reg = nmse_loss(reg_hat, lymph_count)\n",
        "          loss = loss_classification + loss_reg\n",
        "          val_loss += loss.item()\n",
        "          val_reg_loss += loss_reg.item()\n",
        "          val_class_loss += loss_classification.item()\n",
        "          pred = torch.round(y_hat)\n",
        "          val_b_acc += 0.5*(1/n_0_val)*(pred.int() == y_true.int()).sum().item() if y_true.int() == 0 else 0.5*(1/n_1_val)*(pred.int() == y_true.int()).sum().item()\n",
        "          val_acc += (pred.int() == y_true.int()).sum().item()\n",
        "\n",
        "        val_acc /= len(valloader)\n",
        "        val_loss /= len(valloader)\n",
        "        val_reg_loss /= len(valloader)\n",
        "        val_class_loss /= len(valloader)\n",
        "        val_b_acc = np.round(val_b_acc, 3)\n",
        "        val_acc = np.round(val_acc, 3)\n",
        "        val_loss = np.round(val_loss, 3)\n",
        "        val_class_loss = np.round(val_class_loss, 3)\n",
        "        val_reg_loss = np.round(val_reg_loss, 3)\n",
        "        print(f'Val balanced accuracy: {val_b_acc}, Val accuracy: {val_acc}, Val loss: {val_loss}, Val classification loss: {val_class_loss}, Val regression loss: {val_reg_loss}')\n",
        "\n",
        "      if val_loss < best_val_loss:\n",
        "        n_wt_improvement_lr = 0\n",
        "        n_wt_improvement_stop = 0\n",
        "        best_val_loss = val_loss\n",
        "        best_b_acc = val_b_acc\n",
        "        best_dict = deepcopy(model.state_dict())\n",
        "\n",
        "      else:\n",
        "        n_wt_improvement_lr += 1\n",
        "        n_wt_improvement_stop += 1\n",
        "        if n_wt_improvement_stop == patience_early_stopping:\n",
        "          break\n",
        "        if n_wt_improvement_lr == patience_lr:\n",
        "          n_wt_improvement_lr = 0\n",
        "          for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] *= lr_decay\n",
        "          print(f\"Change of learning rate. Now lr = {optimizer.param_groups[0]['lr']}\")\n",
        "\n",
        "      print('-------------------------------------------------------------')\n",
        "\n",
        "    score += best_b_acc\n",
        "\n",
        "  print(f'The mean score obtained with cross-validation is {score/nb_folds}')\n",
        "  return score/nb_folds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_score = cv_multitask(train_datasets_list, val_datasets_list, n_list, \"ResNetMultiTaskModel\", device)"
      ],
      "metadata": {
        "id": "jyxJHCTd8q1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cv_onetask(train_datasets_list, val_datasets_list, n_list, name_model, device, batch_size=1, lr=1e-3, max_epochs=100, patience_early_stopping=10, patience_lr=5, lr_decay=0.1, score=0):\n",
        "\n",
        "  nb_folds = len(train_datasets_list)\n",
        "\n",
        "  for i in range(nb_folds):\n",
        "    print('----------------------------------------------------------')\n",
        "    print(f'Fold number {i+1}')\n",
        "    print('----------------------------------------------------------')\n",
        "    if name_model == \"ResNetOneTaskModel\":\n",
        "      model = ResNetOneTaskModel()\n",
        "    model.to(device)\n",
        "    valset = val_datasets_list[i]\n",
        "    valloader = DataLoader(valset, shuffle=True)\n",
        "    n_0_val, n_1_val = n_list[i]\n",
        "    trainset = torch.utils.data.ConcatDataset([train_datasets_list[j] for j in range(nb_folds) if j !=i])\n",
        "    trainloader = DataLoader(trainset, shuffle=True)\n",
        "    n_0_train, n_1_train = np.array([n_list[j] for j in range(nb_folds) if j!=i]).sum(axis=0)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    n_train = n_0_train + n_1_train\n",
        "    weights_train = torch.Tensor([n_train/n_0_train, n_train/n_1_train])\n",
        "    n_val = n_0_val + n_1_val\n",
        "    weights_val = torch.Tensor([n_val/n_0_val, n_val/n_1_val])\n",
        "\n",
        "    best_val_loss = 1e8\n",
        "    n_wt_improvement_lr = 0 # Nombre d'epoch consécutives sans dépasser le meilleur score depuis le dernier changement de lr\n",
        "    n_wt_improvement_stop = 0 # Nombre d'epoch consécutives sans dépasser le meilleur score\n",
        "    best_dict = deepcopy(model.state_dict())\n",
        "    best_b_acc = 0\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "      print(f'Epoch: {epoch+1}')\n",
        "\n",
        "      model.train()\n",
        "      train_loss =  0\n",
        "      train_acc = 0\n",
        "      train_b_acc = 0\n",
        "      loss = 0\n",
        "      for i, data in enumerate(tqdm(trainloader, desc=\"Train\")):\n",
        "        images, age, lymph_count, gender, features = data['images'], data['age'].to(device), data['lymph_count'].to(device), data['gender'].to(device), data['features'].to(device)\n",
        "        y_hat = model(images, age, lymph_count, gender, features).to(device)\n",
        "        y_true = data['label'].float().unsqueeze(0).to(device)\n",
        "        loss_classification = weighted_binary_cross_entropy(y_hat, y_true, weights=weights_train)\n",
        "        loss += loss_classification\n",
        "        train_loss += loss_classification.item()\n",
        "        if (i+1) % batch_size ==0:\n",
        "          loss /= batch_size\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          optimizer.zero_grad()\n",
        "          loss = 0\n",
        "        elif (i+1) == len(trainloader):\n",
        "          loss /= (len(trainloader) % batch_size)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          optimizer.zero_grad()\n",
        "          loss = 0\n",
        "        pred = torch.round(y_hat)\n",
        "        train_b_acc += 0.5*(1/n_0_train)*(pred.int() == y_true.int()).sum().item() if y_true.int() == 0 else 0.5*(1/n_1_train)*(pred.int() == y_true.int()).sum().item()\n",
        "        train_acc += (pred.int() == y_true.int()).sum().item()\n",
        "\n",
        "      train_acc /= len(trainloader)\n",
        "      train_loss /= len(trainloader)\n",
        "      train_b_acc = np.round(train_b_acc, 3)\n",
        "      train_acc = np.round(train_acc, 3)\n",
        "      train_loss = np.round(train_loss, 3)\n",
        "      print(f'Train balanced accuracy: {train_b_acc}, Train accuracy: {train_acc}, Train loss: {train_loss}')\n",
        "\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "        val_loss =  0\n",
        "        val_acc = 0\n",
        "        val_b_acc = 0\n",
        "        for data in tqdm(valloader, desc=\"Validation\"):\n",
        "          images, age, lymph_count, gender, features = data['images'], data['age'].to(device), data['lymph_count'].to(device), data['gender'].to(device), data['features'].to(device)\n",
        "          y_hat = model(images, age, lymph_count, gender, features)\n",
        "          y_hat = y_hat.to(device)\n",
        "          y_true = data['label'].float().to(device)\n",
        "          loss_classification = weighted_binary_cross_entropy(y_hat, y_true, weights=weights_val)\n",
        "          loss = loss_classification\n",
        "          val_loss += loss.item()\n",
        "          pred = torch.round(y_hat)\n",
        "          val_b_acc += 0.5*(1/n_0_val)*(pred.int() == y_true.int()).sum().item() if y_true.int() == 0 else 0.5*(1/n_1_val)*(pred.int() == y_true.int()).sum().item()\n",
        "          val_acc += (pred.int() == y_true.int()).sum().item()\n",
        "\n",
        "        val_acc /= len(valloader)\n",
        "        val_loss /= len(valloader)\n",
        "        val_b_acc = np.round(val_b_acc, 3)\n",
        "        val_acc = np.round(val_acc, 3)\n",
        "        val_loss = np.round(val_loss, 3)\n",
        "        print(f'Val balanced accuracy: {val_b_acc}, Val accuracy: {val_acc}, Val loss: {val_loss}')\n",
        "\n",
        "      if val_loss < best_val_loss:\n",
        "        n_wt_improvement_lr = 0\n",
        "        n_wt_improvement_stop = 0\n",
        "        best_val_loss = val_loss\n",
        "        best_b_acc = val_b_acc\n",
        "        best_dict = deepcopy(model.state_dict())\n",
        "\n",
        "      else:\n",
        "        n_wt_improvement_lr += 1\n",
        "        n_wt_improvement_stop += 1\n",
        "        if n_wt_improvement_stop == patience_early_stopping:\n",
        "          break\n",
        "        if n_wt_improvement_lr == patience_lr:\n",
        "          n_wt_improvement_lr = 0\n",
        "          for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] *= lr_decay\n",
        "          print(f\"Change of learning rate. Now lr = {optimizer.param_groups[0]['lr']}\")\n",
        "\n",
        "      print('-------------------------------------------------------------')\n",
        "\n",
        "    score += best_b_acc\n",
        "\n",
        "  print(f'The mean score obtained with cross-validation is {score/nb_folds}')\n",
        "  return score/nb_folds"
      ],
      "metadata": {
        "id": "wPWXzSn98AkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_score = cv_onetask(train_datasets_list, val_datasets_list, n_list, \"ResNetOneTaskModel\", device)"
      ],
      "metadata": {
        "id": "R6w1GhAe-Es1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upSvSSvGHf2f"
      },
      "source": [
        "## Train classicaly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixgqjnq4MsOq"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "i = 1\n",
        "\n",
        "trainset = torch.utils.data.ConcatDataset([train_datasets_list[j] for j in range(nb_folds) if j !=i])\n",
        "trainloader = DataLoader(trainset, shuffle=True)\n",
        "\n",
        "n_0_val, n_1_val = n_list[i]\n",
        "n_val = n_0_val + n_1_val\n",
        "weights_val = torch.Tensor([n_val/n_0_val, n_val/n_1_val])\n",
        "\n",
        "valset = val_datasets_list[i]\n",
        "valloader = DataLoader(valset)\n",
        "\n",
        "n_0_train, n_1_train = np.array([n_list[j] for j in range(nb_folds) if j!=i]).sum(axis=0)\n",
        "n_train = n_0_train + n_1_train\n",
        "weights_train = torch.Tensor([n_train/n_0_train, n_train/n_1_train])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from copy import deepcopy\n",
        "from google.colab import files\n",
        "\n",
        "def train_onetask(model, trainloader, valloader, device, n_0_train, n_1_train, n_0_val, n_1_val, batch_size=1, lr=1e-3, lr_decay=0.1, max_epochs=25, patience_lr=5, patience_early_stopping=10, wandb_log=False, wandb_name=None, wandb_config=None):\n",
        "\n",
        "  model.to(device)\n",
        "  optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "  best_val_loss = 1e8\n",
        "  n_wt_improvement_lr = 0 # Nombre d'epoch consécutives sans dépasser le meilleur score depuis le dernier changement de lr\n",
        "  n_wt_improvement_stop = 0 # Nombre d'epoch consécutives sans dépasser le meilleur score\n",
        "  best_dict = deepcopy(model.state_dict())\n",
        "\n",
        "  n_train = n_0_train + n_1_train\n",
        "  weights_train = torch.Tensor([n_train/n_0_train, n_train/n_1_train])\n",
        "\n",
        "  n_val = n_0_val + n_1_val\n",
        "  weights_val = torch.Tensor([n_val/n_0_val, n_val/n_1_val])\n",
        "\n",
        "  if wandb_log:\n",
        "    wandb.init(\n",
        "        project=\"DLMI-challenge\",\n",
        "        name=wandb_name,\n",
        "        config=wandb_config,\n",
        "        entity='fous-du-wan'\n",
        "    )\n",
        "\n",
        "  for epoch in range(max_epochs):\n",
        "    print(f'Epoch: {epoch+1}')\n",
        "\n",
        "    model.train()\n",
        "    train_loss =  0\n",
        "    train_acc = 0\n",
        "    train_b_acc = 0\n",
        "    loss = 0\n",
        "    for i, data in enumerate(tqdm(trainloader, desc=\"Train\")):\n",
        "      images, age, lymph_count, gender, features = data['images'], data['age'].to(device), data['lymph_count'].to(device), data['gender'].to(device), data['features'].to(device)\n",
        "      y_hat = model(images, age, lymph_count, gender, features).to(device)\n",
        "      y_true = data['label'].float().unsqueeze(0).to(device)\n",
        "      loss_classification = weighted_binary_cross_entropy(y_hat, y_true, weights=weights_train)\n",
        "      loss += loss_classification\n",
        "      train_loss += loss_classification.item()\n",
        "      if (i+1) % batch_size ==0:\n",
        "        loss /= batch_size\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        loss = 0\n",
        "      elif (i+1) == len(trainloader):\n",
        "        loss /= (len(trainloader) % batch_size)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        loss = 0\n",
        "      pred = torch.round(y_hat)\n",
        "      train_b_acc += 0.5*(1/n_0_train)*(pred.int() == y_true.int()).sum().item() if y_true.int() == 0 else 0.5*(1/n_1_train)*(pred.int() == y_true.int()).sum().item()\n",
        "      train_acc += (pred.int() == y_true.int()).sum().item()\n",
        "\n",
        "    train_acc /= len(trainloader)\n",
        "    train_loss /= len(trainloader)\n",
        "    train_b_acc = np.round(train_b_acc, 3)\n",
        "    train_acc = np.round(train_acc, 3)\n",
        "    train_loss = np.round(train_loss, 3)\n",
        "    print(f'Train balanced accuracy: {train_b_acc}, Train accuracy: {train_acc}, Train loss: {train_loss}')\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      val_loss =  0\n",
        "      val_acc = 0\n",
        "      val_b_acc = 0\n",
        "      for data in tqdm(valloader, desc=\"Validation\"):\n",
        "        images, age, lymph_count, gender, features = data['images'], data['age'].to(device), data['lymph_count'].to(device), data['gender'].to(device), data['features'].to(device)\n",
        "        y_hat = model(images, age, lymph_count, gender, features)\n",
        "        y_hat = y_hat.to(device)\n",
        "        y_true = data['label'].float().to(device)\n",
        "        loss_classification = weighted_binary_cross_entropy(y_hat, y_true, weights=weights_val)\n",
        "        loss = loss_classification\n",
        "        val_loss += loss.item()\n",
        "        pred = torch.round(y_hat)\n",
        "        val_b_acc += 0.5*(1/n_0_val)*(pred.int() == y_true.int()).sum().item() if y_true.int() == 0 else 0.5*(1/n_1_val)*(pred.int() == y_true.int()).sum().item()\n",
        "        val_acc += (pred.int() == y_true.int()).sum().item()\n",
        "\n",
        "      val_acc /= len(valloader)\n",
        "      val_loss /= len(valloader)\n",
        "      val_b_acc = np.round(val_b_acc, 3)\n",
        "      val_acc = np.round(val_acc, 3)\n",
        "      val_loss = np.round(val_loss, 3)\n",
        "      print(f'Val balanced accuracy: {val_b_acc}, Val accuracy: {val_acc}, Val loss: {val_loss}')\n",
        "\n",
        "    if wandb_log:\n",
        "      wandb.log({\"val_loss\": val_loss, \"val_balanced_acc\": val_b_acc, \"train_loss\": train_loss, 'train_balanced_acc': train_b_acc})\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "      n_wt_improvement_lr = 0\n",
        "      n_wt_improvement_stop = 0\n",
        "      best_val_loss = val_loss\n",
        "      best_dict = deepcopy(model.state_dict())\n",
        "      torch.save(best_dict, 'best_model.pth')\n",
        "\n",
        "    else:\n",
        "      n_wt_improvement_lr += 1\n",
        "      n_wt_improvement_stop += 1\n",
        "      if n_wt_improvement_stop == patience_early_stopping:\n",
        "        break\n",
        "      if n_wt_improvement_lr == patience_lr:\n",
        "        n_wt_improvement_lr = 0\n",
        "        for param_group in optimizer.param_groups:\n",
        "          param_group['lr'] *= lr_decay\n",
        "        print(f\"Change of learning rate. Now lr = {optimizer.param_groups[0]['lr']}\")\n",
        "\n",
        "    print('-------------------------------------------------------------')\n",
        "\n",
        "  if wandb_log:\n",
        "    wandb.finish()\n",
        "\n",
        "  files.download('/content/best_model.pth')\n",
        "\n",
        "  return best_dict"
      ],
      "metadata": {
        "id": "h5AV2t8KHQWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNetOneTaskModel()\n",
        "model.to(device)\n",
        "\n",
        "best_dict = train_onetask(model, trainloader, valloader, device, n_0_train, n_1_train, n_0_val, n_1_val)"
      ],
      "metadata": {
        "id": "R891jGzI2ya1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_multitask(model, trainloader, valloader, device, n_0_train, n_1_train, n_0_val, n_1_val, batch_size=1, max_epochs=25, patience_lr=5, patience_early_stopping=10, lr=1e-3, lr_decay=0.1, wandb_log=False, wandb_name=None, wandb_config=None):\n",
        "\n",
        "  model.to(device)\n",
        "  optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "  best_val_loss = 1e8\n",
        "  n_wt_improvement_lr = 0\n",
        "  n_wt_improvement_stop = 0\n",
        "  best_dict = deepcopy(model.state_dict())\n",
        "\n",
        "  n_train = n_0_train + n_1_train\n",
        "  weights_train = torch.Tensor([n_train/n_0_train, n_train/n_1_train])\n",
        "\n",
        "  n_val = n_0_val + n_1_val\n",
        "  weights_val = torch.Tensor([n_val/n_0_val, n_val/n_1_val])\n",
        "\n",
        "  if wandb_log:\n",
        "    wandb.init(\n",
        "        project=\"DLMI-challenge\",\n",
        "        name=wandb_name,\n",
        "        config=wandb_config,\n",
        "        entity='fous-du-wan'\n",
        "    )\n",
        "\n",
        "  for epoch in range(max_epochs):\n",
        "    print(f'Epoch: {epoch+1}')\n",
        "\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    train_class_loss = 0\n",
        "    train_reg_loss = 0\n",
        "    train_acc = 0\n",
        "    train_b_acc = 0\n",
        "    loss = 0\n",
        "    for i, data in enumerate(tqdm(trainloader, desc=\"Train\")):\n",
        "      images, age, lymph_count, gender, features = data['images'], data['age'].to(device), data['lymph_count'].to(device), data['gender'].to(device), data['features'].to(device)\n",
        "      y_hat, reg_hat = model(images, age, lymph_count, gender, features)\n",
        "      y_hat, reg_hat = y_hat.to(device), reg_hat.to(device)\n",
        "      y_true = data['label'].float().unsqueeze(0).to(device)\n",
        "      loss_classification = weighted_binary_cross_entropy(y_hat, y_true, weights=weights_train)\n",
        "      loss_reg = nmse_loss(reg_hat, lymph_count)\n",
        "      loss += loss_classification + loss_reg\n",
        "      train_loss += loss_classification.item() + loss_reg.item()\n",
        "      train_class_loss += loss_classification.item()\n",
        "      train_reg_loss += loss_reg.item()\n",
        "      if (i+1) % batch_size ==0:\n",
        "        loss /= batch_size\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        loss = 0\n",
        "      elif (i+1) == len(trainloader):\n",
        "        loss /= (len(trainloader) % batch_size)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        loss = 0\n",
        "      pred = torch.round(y_hat)\n",
        "      train_b_acc += 0.5*(1/n_0_train)*(pred.int() == y_true.int()).sum().item() if y_true.int() == 0 else 0.5*(1/n_1_train)*(pred.int() == y_true.int()).sum().item()\n",
        "      train_acc += (pred.int() == y_true.int()).sum().item()\n",
        "\n",
        "    train_acc /= len(trainloader)\n",
        "    train_loss /= len(trainloader)\n",
        "    train_class_loss /= len(trainloader)\n",
        "    train_reg_loss /= len(trainloader)\n",
        "    train_b_acc = np.round(train_b_acc, 3)\n",
        "    train_acc = np.round(train_acc, 3)\n",
        "    train_loss = np.round(train_loss, 3)\n",
        "    train_class_loss = np.round(train_class_loss, 3)\n",
        "    train_reg_loss = np.round(train_reg_loss, 3)\n",
        "    print(f'Train balanced accuracy: {train_b_acc}, Train accuracy: {train_acc}, Train loss: {train_loss}, Train classification loss: {train_class_loss}, Train regression loss: {train_reg_loss}')\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      val_loss =  0\n",
        "      val_acc = 0\n",
        "      val_b_acc = 0\n",
        "      val_reg_loss = 0\n",
        "      val_class_loss = 0\n",
        "      for data in tqdm(valloader, desc=\"Validation\"):\n",
        "        images, age, lymph_count, gender, features = data['images'], data['age'].to(device), data['lymph_count'].to(device), data['gender'].to(device), data['features'].to(device)\n",
        "        y_hat, reg_hat = model(images, age, lymph_count, gender, features)\n",
        "        y_hat = y_hat.to(device)\n",
        "        reg_hat = reg_hat.to(device)\n",
        "        y_true = data['label'].float().to(device)\n",
        "        loss_classification = weighted_binary_cross_entropy(y_hat, y_true, weights=weights_val)\n",
        "        loss_reg = nmse_loss(reg_hat, lymph_count)\n",
        "        loss = loss_classification + loss_reg\n",
        "        val_loss += loss.item()\n",
        "        val_reg_loss += loss_reg.item()\n",
        "        val_class_loss += loss_classification.item()\n",
        "        pred = torch.round(y_hat)\n",
        "        val_b_acc += 0.5*(1/n_0_val)*(pred.int() == y_true.int()).sum().item() if y_true.int() == 0 else 0.5*(1/n_1_val)*(pred.int() == y_true.int()).sum().item()\n",
        "        val_acc += (pred.int() == y_true.int()).sum().item()\n",
        "\n",
        "      val_acc /= len(valloader)\n",
        "      val_loss /= len(valloader)\n",
        "      val_reg_loss /= len(valloader)\n",
        "      val_class_loss /= len(valloader)\n",
        "      val_b_acc = np.round(val_b_acc, 3)\n",
        "      val_acc = np.round(val_acc, 3)\n",
        "      val_loss = np.round(val_loss, 3)\n",
        "      val_class_loss = np.round(val_class_loss, 3)\n",
        "      val_reg_loss = np.round(val_reg_loss, 3)\n",
        "      print(f'Val balanced accuracy: {val_b_acc}, Val accuracy: {val_acc}, Val loss: {val_loss}, Val classification loss: {val_class_loss}, Val regression loss: {val_reg_loss}')\n",
        "\n",
        "    if wandb_log:\n",
        "      wandb.log({\"val_loss\": val_loss, \"val_balanced_acc\": val_b_acc, \"val_class_loss\": val_class_loss, \"val_reg_loss\": val_reg_loss, \"train_loss\": train_loss, 'train_balanced_acc': train_b_acc, \"train_class_loss\": train_class_loss, \"train_reg_loss\": train_reg_loss})\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "      n_wt_improvement_lr = 0\n",
        "      n_wt_improvement_stop = 0\n",
        "      best_val_loss = val_loss\n",
        "      best_dict = deepcopy(model.state_dict())\n",
        "      torch.save(best_dict, 'best_model.pth')\n",
        "\n",
        "    else:\n",
        "      n_wt_improvement_lr += 1\n",
        "      n_wt_improvement_stop += 1\n",
        "      if n_wt_improvement_stop == patience_early_stopping:\n",
        "        break\n",
        "      if n_wt_improvement_lr == patience_lr:\n",
        "        n_wt_improvement_lr = 0\n",
        "        for param_group in optimizer.param_groups:\n",
        "          param_group['lr'] *= lr_decay\n",
        "        print(f\"Change of learning rate. Now lr = {optimizer.param_groups[0]['lr']}\")\n",
        "\n",
        "    print('-------------------------------------------------------------')\n",
        "\n",
        "  if wandb_log:\n",
        "    wandb.finish()\n",
        "\n",
        "  files.download('/content/best_model.pth')\n",
        "\n",
        "  return best_dict"
      ],
      "metadata": {
        "id": "LSlB66wKJhI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConvNextMultiTaskModel()\n",
        "model.to(device)\n",
        "\n",
        "best_dict = train_multitask(model, trainloader, valloader, device, n_0_train, n_1_train, n_0_val, n_1_val)"
      ],
      "metadata": {
        "id": "eEf5iaCHNkDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpE1WpT_o-9i"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHi1GxIqANRt"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "test_cases = []\n",
        "for data in tqdm(testloader):\n",
        "    images, age, lymph_count, gender, features = data['images'], data['age'].to(device), data['lymph_count'].to(device), data['gender'].to(device), data['features'].to(device)\n",
        "    y_hat, reg_hat = model(images, age, lymph_count, gender, features)\n",
        "    y_hat = y_hat.to(device)\n",
        "    pred = torch.round(y_hat)\n",
        "    test_cases.append((data['id'][0], pred.int().item()))\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df_submission = pd.DataFrame(test_cases, columns=['Id', 'Predicted'])\n",
        "\n",
        "df_submission.to_csv('test_transform.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "hvGU55tjPBIL",
        "aR-eha_AE-BQ",
        "fl4v__ZKfksI"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}